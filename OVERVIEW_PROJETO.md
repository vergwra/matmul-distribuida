# Overview do Projeto - MultiplicaÃ§Ã£o de Matrizes DistribuÃ­da

## ðŸ“‹ SumÃ¡rio Executivo

Este projeto implementa um sistema de **multiplicaÃ§Ã£o de matrizes distribuÃ­da** usando **computaÃ§Ã£o paralela e concorrente** em Python. O sistema utiliza uma arquitetura **cliente-servidor** com **sockets TCP** e **threading** para distribuir o processamento entre mÃºltiplos clientes.

---

## ðŸ—ï¸ Arquitetura do Sistema

### Estrutura de DiretÃ³rios

```
matmul-distribuida/
â”œâ”€â”€ src/matmul/
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â””â”€â”€ main.py          # Servidor coordenador
â”‚   â”œâ”€â”€ client/
â”‚   â”‚   â””â”€â”€ main.py          # Cliente worker
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ protocol.py      # Protocolo de comunicaÃ§Ã£o
â”‚       â””â”€â”€ matrix_utils.py  # OperaÃ§Ãµes com matrizes
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Componentes Principais

1. **Servidor (`server/main.py`)**: Coordenador central que distribui tarefas
2. **Cliente (`client/main.py`)**: Worker que processa blocos de matriz
3. **Protocolo (`utils/protocol.py`)**: ComunicaÃ§Ã£o via JSON sobre TCP
4. **UtilitÃ¡rios (`utils/matrix_utils.py`)**: OperaÃ§Ãµes matemÃ¡ticas com matrizes

---

## ðŸ”„ Fluxo de ExecuÃ§Ã£o Completo

### 1ï¸âƒ£ InicializaÃ§Ã£o do Servidor

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVIDOR INICIA                         â”‚
â”‚ - Define HOST:PORT (127.0.0.1:5000)     â”‚
â”‚ - Solicita dimensÃµes das matrizes       â”‚
â”‚ - Gera matrizes A e B aleatoriamente    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 78-91):
- LÃª dimensÃµes: `rows_A`, `cols_A`, `cols_B`
- Gera `A` (rows_A Ã— cols_A) e `B` (cols_A Ã— cols_B)

### 2ï¸âƒ£ CÃ¡lculo Sequencial (Baseline)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXECUÃ‡ÃƒO SEQUENCIAL                     â”‚
â”‚ - Calcula C_seq = A Ã— B localmente      â”‚
â”‚ - Mede tempo de execuÃ§Ã£o                â”‚
â”‚ - Serve como baseline para comparaÃ§Ã£o   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 96-102):
- `C_seq = multiply(A, B)` - multiplicaÃ§Ã£o tradicional O(nÂ³)
- Armazena tempo para comparaÃ§Ã£o com versÃ£o distribuÃ­da

### 3ï¸âƒ£ DivisÃ£o da Matriz A em Blocos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARTICIONAMENTO                         â”‚
â”‚ - Divide A em N blocos horizontais      â”‚
â”‚ - N = nÃºmero de clientes esperados      â”‚
â”‚ - Cada bloco tem ~(rows_A/N) linhas     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Exemplo: A(6Ã—4) com 2 clientes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bloco 0 â”‚ â†’ 3 linhas â†’ Cliente 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bloco 1 â”‚ â†’ 3 linhas â†’ Cliente 2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 105-106):
- `blocks = split_matrix_by_rows(A, num_clients)`
- FunÃ§Ã£o em `matrix_utils.py` (linhas 41-66) distribui linhas uniformemente

### 4ï¸âƒ£ Servidor Aguarda ConexÃµes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVIDOR ESCUTA                         â”‚
â”‚ - Cria socket TCP                       â”‚
â”‚ - Bind em HOST:PORT                     â”‚
â”‚ - Listen para N clientes                â”‚
â”‚ - Aceita conexÃµes sequencialmente       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 113-126):
- Socket com `SO_REUSEADDR` para reutilizaÃ§Ã£o rÃ¡pida
- Loop aceita exatamente `num_clients` conexÃµes

### 5ï¸âƒ£ Clientes Conectam e Recebem Tarefas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLIENTE 1   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   SERVIDOR   â”‚
â”‚              â”‚  Envia:            â”‚              â”‚
â”‚              â”‚  - block_index: 0  â”‚              â”‚
â”‚              â”‚  - A_block (3Ã—4)   â”‚              â”‚
â”‚              â”‚  - B (4Ã—5)         â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                                    â”‚
       â”‚                                    â–¼
       â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  CLIENTE 2   â”‚
                                    â”‚              â”‚
                                    â”‚ block_index:1â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Protocolo de ComunicaÃ§Ã£o** (`protocol.py`):

```python
# Mensagem enviada pelo servidor
{
    "type": "task",
    "block_index": 0,
    "A_block": [[1, 2, 3, 4], [5, 6, 7, 8], ...],
    "B": [[...], [...], ...]
}
```

**Formato de TransmissÃ£o**:
1. **4 bytes**: Tamanho do JSON (big-endian)
2. **N bytes**: Payload JSON em UTF-8

### 6ï¸âƒ£ Processamento Paralelo nos Clientes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLIENTE PROCESSA                         â”‚
â”‚ 1. Recebe A_block e B                    â”‚
â”‚ 2. Calcula C_block = A_block Ã— B         â”‚
â”‚ 3. Envia resultado de volta              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Exemplo:
A_block (3Ã—4) Ã— B (4Ã—5) = C_block (3Ã—5)
```

**CÃ³digo relevante** (`client/main.py`, linhas 38-52):
- `C_block = multiply(A_block, B)` - multiplicaÃ§Ã£o local
- Envia resposta com `block_index` para ordenaÃ§Ã£o

**Algoritmo de MultiplicaÃ§Ã£o** (`matrix_utils.py`, linhas 15-39):
```python
# MultiplicaÃ§Ã£o clÃ¡ssica O(nÂ³)
for i in range(n):
    for j in range(p):
        soma = 0
        for k in range(m):
            soma += A[i][k] * B[k][j]
        C[i][j] = soma
```

### 7ï¸âƒ£ Threading no Servidor

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVIDOR CRIA THREADS                   â”‚
â”‚                                         â”‚
â”‚ Thread 1 â”€â”€â–º handle_client(Cliente 1)  â”‚
â”‚ Thread 2 â”€â”€â–º handle_client(Cliente 2)  â”‚
â”‚ ...                                     â”‚
â”‚ Thread N â”€â”€â–º handle_client(Cliente N)  â”‚
â”‚                                         â”‚
â”‚ Todas executam CONCORRENTEMENTE         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 130-136):
- Cada conexÃ£o gera uma thread daemon
- Threads executam `handle_client()` em paralelo
- Lock protege dicionÃ¡rio compartilhado `results`

### 8ï¸âƒ£ SincronizaÃ§Ã£o e Coleta de Resultados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SINCRONIZAÃ‡ÃƒO                           â”‚
â”‚                                         â”‚
â”‚ results = {}  â—„â”€â”€â”€ Lock protegido      â”‚
â”‚                                         â”‚
â”‚ Thread 1 â”€â”€â–º results[0] = C_block_0    â”‚
â”‚ Thread 2 â”€â”€â–º results[1] = C_block_1    â”‚
â”‚                                         â”‚
â”‚ servidor.join() â”€â”€â–º Aguarda todas      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 60-62):
```python
with lock:
    results[result_block_index] = C_block
```

### 9ï¸âƒ£ ReconstruÃ§Ã£o da Matriz Final

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONCATENAÃ‡ÃƒO                            â”‚
â”‚                                         â”‚
â”‚ results = {0: C_block_0, 1: C_block_1}  â”‚
â”‚                                         â”‚
â”‚ C = []                                  â”‚
â”‚ for idx in sorted(results.keys()):     â”‚
â”‚     C.extend(results[idx])             â”‚
â”‚                                         â”‚
â”‚ C = [linha1, linha2, ..., linha6]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 151-153):
- Ordena blocos por Ã­ndice
- Concatena linhas na ordem correta

### ðŸ”Ÿ ValidaÃ§Ã£o e ComparaÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VALIDAÃ‡ÃƒO                               â”‚
â”‚                                         â”‚
â”‚ C_seq == C_distribuÃ­do? âœ“               â”‚
â”‚                                         â”‚
â”‚ Tempo sequencial:   0.0023s             â”‚
â”‚ Tempo distribuÃ­do:  0.0015s             â”‚
â”‚ Speedup: 1.53x                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo relevante** (`server/main.py`, linhas 159-161):
- Compara resultado distribuÃ­do com baseline
- Mede tempo total de execuÃ§Ã£o distribuÃ­da

---

## ðŸ§µ Conceitos de ComputaÃ§Ã£o Paralela e Concorrente

### Paralelismo de Dados (Data Parallelism)

O projeto usa **paralelismo de dados** ao dividir a matriz A em blocos:

```
Tarefa: A Ã— B = C

DecomposiÃ§Ã£o:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ A_0     â”‚  Ã—  â”‚ B â”‚  =  â”‚ C_0     â”‚  â† Cliente 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ A_1     â”‚  Ã—  â”‚ B â”‚  =  â”‚ C_1     â”‚  â† Cliente 2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Propriedade: Cada cliente executa a MESMA operaÃ§Ã£o (multiplicaÃ§Ã£o)
             em DADOS DIFERENTES (blocos de A)
```

### ConcorrÃªncia com Threading

**Threads no Servidor**:
- MÃºltiplas threads executam simultaneamente
- Compartilham memÃ³ria (dicionÃ¡rio `results`)
- SincronizaÃ§Ã£o via `threading.Lock()`

```python
# RegiÃ£o crÃ­tica protegida
with lock:
    results[block_index] = C_block  # Acesso exclusivo
```

### ComunicaÃ§Ã£o via Sockets TCP

**Modelo Cliente-Servidor**:
- **Servidor**: Coordenador central (1 processo)
- **Clientes**: Workers distribuÃ­dos (N processos)
- **Protocolo**: JSON sobre TCP com framing

**Vantagens**:
- âœ… Clientes podem estar em mÃ¡quinas diferentes
- âœ… Protocolo simples e extensÃ­vel
- âœ… Confiabilidade do TCP

---

## ðŸ“Š AnÃ¡lise de Desempenho

### Complexidade Computacional

**MultiplicaÃ§Ã£o de Matrizes**:
- A (n Ã— m) Ã— B (m Ã— p) = C (n Ã— p)
- Complexidade: **O(n Ã— m Ã— p)**

**VersÃ£o Sequencial**:
- Tempo: T_seq = O(n Ã— m Ã— p)

**VersÃ£o DistribuÃ­da com k clientes**:
- Cada cliente processa n/k linhas
- Tempo ideal: T_dist = O((n/k) Ã— m Ã— p)
- **Speedup teÃ³rico**: k

### Overhead da DistribuiÃ§Ã£o

**Custos adicionais**:
1. **SerializaÃ§Ã£o**: ConversÃ£o matriz â†’ JSON
2. **TransmissÃ£o**: Envio via rede (mesmo local)
3. **SincronizaÃ§Ã£o**: Lock e join de threads
4. **ReconstruÃ§Ã£o**: ConcatenaÃ§Ã£o de blocos

**Trade-off**:
- Matrizes pequenas: Overhead > Ganho paralelo
- Matrizes grandes: Ganho paralelo > Overhead

---

## ðŸ”§ Detalhamento TÃ©cnico das FunÃ§Ãµes

### `protocol.py`

#### `send_json(sock, data)`
**PropÃ³sito**: Envia dicionÃ¡rio Python via socket

**ImplementaÃ§Ã£o**:
```python
1. Serializa dict â†’ JSON string
2. Codifica string â†’ bytes UTF-8
3. Calcula tamanho (4 bytes big-endian)
4. Envia: [tamanho][payload]
```

**Por que usar framing?**
- TCP Ã© stream-based (nÃ£o tem delimitadores de mensagem)
- CabeÃ§alho de tamanho permite ler exatamente N bytes

#### `recv_json(sock)`
**PropÃ³sito**: Recebe JSON do socket

**ImplementaÃ§Ã£o**:
```python
1. LÃª 4 bytes â†’ tamanho
2. LÃª exatamente 'tamanho' bytes â†’ payload
3. Decodifica UTF-8 â†’ string
4. Deserializa JSON â†’ dict
```

#### `recv_exactly(sock, size)`
**PropÃ³sito**: Garante leitura completa de N bytes

**Por que necessÃ¡rio?**
- `sock.recv(N)` pode retornar < N bytes
- Loop acumula chunks atÃ© completar N bytes

---

### `matrix_utils.py`

#### `generate_matrix(rows, cols, min_val, max_val)`
**PropÃ³sito**: Cria matriz aleatÃ³ria para testes

**ImplementaÃ§Ã£o**:
```python
[[random.randint(min_val, max_val) for _ in range(cols)]
 for _ in range(rows)]
```

#### `multiply(A, B)`
**PropÃ³sito**: MultiplicaÃ§Ã£o clÃ¡ssica de matrizes

**Algoritmo**:
```
Para cada elemento C[i][j]:
    C[i][j] = Î£(k=0 atÃ© m-1) A[i][k] Ã— B[k][j]
```

**ValidaÃ§Ã£o**:
- Verifica compatibilidade: `cols(A) == rows(B)`

#### `split_matrix_by_rows(A, num_parts)`
**PropÃ³sito**: Divide matriz em blocos horizontais

**Algoritmo**:
```python
block_size = rows // num_parts
remainder = rows % num_parts

# Distribui linhas extras nos primeiros blocos
for i in range(num_parts):
    extra = 1 if i < remainder else 0
    tamanho_bloco = block_size + extra
```

**Exemplo**:
- A com 10 linhas, 3 clientes
- Blocos: [4 linhas, 3 linhas, 3 linhas]

---

### `server/main.py`

#### `handle_client(conn, addr, block_index, A_block, B, results, lock)`
**PropÃ³sito**: Thread que gerencia comunicaÃ§Ã£o com 1 cliente

**Fluxo**:
```
1. Monta tarefa (dict com A_block, B, block_index)
2. send_json(tarefa)
3. response = recv_json()
4. Valida tipo de resposta
5. Lock â†’ results[block_index] = C_block
6. Fecha conexÃ£o
```

**Tratamento de Erros**:
- Try/except captura falhas de rede
- Finally garante fechamento do socket

#### `main(num_clients)`
**PropÃ³sito**: FunÃ§Ã£o principal do servidor

**Etapas**:
1. Gera matrizes A e B
2. Calcula baseline sequencial
3. Divide A em blocos
4. Cria socket servidor
5. Loop: aceita N clientes e cria threads
6. Aguarda todas threads (`join()`)
7. ReconstrÃ³i matriz C
8. Valida resultado

---

### `client/main.py`

#### `main(host, port, verbose)`
**PropÃ³sito**: FunÃ§Ã£o principal do cliente

**Fluxo**:
```
1. Conecta ao servidor
2. Recebe tarefa (A_block, B, block_index)
3. Calcula C_block = A_block Ã— B
4. Envia resultado
5. Fecha conexÃ£o
```

**Modo Verbose**:
- Imprime matrizes recebidas e calculadas
- Ãštil para debugging

---

## ðŸš€ Como Executar

### Passo 1: Iniciar o Servidor

```bash
cd /Users/marinavergara/Documents/www/faculdade/matmul-distribuida
python -m matmul.server.main --num-clients 3
```

**SaÃ­da esperada**:
```
[SERVIDOR] Iniciando servidor de multiplicaÃ§Ã£o distribuÃ­da...
[SERVIDOR] Esperando 3 clientes em 127.0.0.1:5000
NÃºmero de linhas da matriz A: 9
NÃºmero de colunas da matriz A (e linhas de B): 6
NÃºmero de colunas da matriz B: 8
[SERVIDOR] Tempo total (sequencial): 0.0012 segundos
[SERVIDOR] A foi dividida em 3 blocos para 3 clientes.
[SERVIDOR] Aguardando conexÃµes dos clientes...
```

### Passo 2: Iniciar Clientes (em terminais separados)

**Terminal 2**:
```bash
python -m matmul.client.main
```

**Terminal 3**:
```bash
python -m matmul.client.main
```

**Terminal 4**:
```bash
python -m matmul.client.main
```

### Passo 3: Observar Resultados

**No servidor**:
```
[SERVIDOR] ConexÃ£o aceita de ('127.0.0.1', 54321) para bloco 0
[SERVIDOR] ConexÃ£o aceita de ('127.0.0.1', 54322) para bloco 1
[SERVIDOR] ConexÃ£o aceita de ('127.0.0.1', 54323) para bloco 2
[SERVIDOR] Recebeu resultado do cliente ('127.0.0.1', 54321) (bloco 0)
[SERVIDOR] Recebeu resultado do cliente ('127.0.0.1', 54322) (bloco 1)
[SERVIDOR] Recebeu resultado do cliente ('127.0.0.1', 54323) (bloco 2)
[SERVIDOR] Tempo total (distribuÃ­do): 0.0089 segundos
[SERVIDOR] Os resultados distribuÃ­do e sequencial sÃ£o iguais? True
```

---

## ðŸŽ¯ Conceitos-Chave para ApresentaÃ§Ã£o

### 1. Paralelismo vs ConcorrÃªncia

**ConcorrÃªncia** (no servidor):
- MÃºltiplas threads gerenciando clientes
- Compartilhamento de memÃ³ria (results dict)
- SincronizaÃ§Ã£o com locks

**Paralelismo** (entre clientes):
- MÃºltiplos processos executando simultaneamente
- Cada um processa bloco independente
- Sem compartilhamento de memÃ³ria

### 2. Escalabilidade

**Horizontal**:
- Adicionar mais clientes â†’ mais paralelismo
- Limitado por overhead de comunicaÃ§Ã£o

**Vertical**:
- Matrizes maiores â†’ melhor aproveitamento
- Overhead fixo diluÃ­do

### 3. Balanceamento de Carga

**EstratÃ©gia atual**: DivisÃ£o estÃ¡tica uniforme
- Cada cliente recebe ~(n/k) linhas
- Assume clientes homogÃªneos

**Melhorias possÃ­veis**:
- DivisÃ£o dinÃ¢mica (work stealing)
- Considerar capacidade de cada cliente

### 4. TolerÃ¢ncia a Falhas

**LimitaÃ§Ãµes atuais**:
- Se 1 cliente falhar, servidor fica bloqueado
- Sem retry ou timeout

**Melhorias possÃ­veis**:
- Timeout nas conexÃµes
- Redistribuir tarefas de clientes falhados

---

## ðŸ“ˆ Experimentos Sugeridos

### Experimento 1: Speedup vs NÃºmero de Clientes

```python
# Testar com 1, 2, 4, 8 clientes
# Matriz fixa: 1000Ã—1000 Ã— 1000Ã—1000
# Medir: T_seq, T_dist(k), Speedup(k) = T_seq / T_dist(k)
```

### Experimento 2: Overhead de ComunicaÃ§Ã£o

```python
# Medir tempo de:
# - SerializaÃ§Ã£o JSON
# - TransmissÃ£o via socket
# - DeserializaÃ§Ã£o
# Comparar com tempo de computaÃ§Ã£o
```

### Experimento 3: Escalabilidade

```python
# Fixar num_clients = 4
# Variar tamanho: 100Ã—100, 500Ã—500, 1000Ã—1000, 2000Ã—2000
# Observar quando distribuÃ­do supera sequencial
```

---

## ðŸ” Pontos Fortes do Projeto

1. âœ… **Arquitetura clara**: SeparaÃ§Ã£o cliente/servidor bem definida
2. âœ… **Protocolo robusto**: Framing evita bugs de parsing
3. âœ… **ValidaÃ§Ã£o**: Compara com resultado sequencial
4. âœ… **MediÃ§Ã£o**: Tempos de execuÃ§Ã£o para anÃ¡lise
5. âœ… **Modularidade**: FunÃ§Ãµes reutilizÃ¡veis em `utils/`

## ðŸš§ LimitaÃ§Ãµes e Melhorias Futuras

### LimitaÃ§Ãµes

1. âŒ **Sem tolerÃ¢ncia a falhas**: Cliente falhando trava servidor
2. âŒ **DivisÃ£o estÃ¡tica**: NÃ£o considera heterogeneidade
3. âŒ **Sem timeout**: Servidor pode esperar indefinidamente
4. âŒ **SerializaÃ§Ã£o ineficiente**: JSON nÃ£o Ã© ideal para arrays numÃ©ricos

### Melhorias Propostas

1. **Usar NumPy**:
   ```python
   # Substituir listas por np.ndarray
   # Serializar com pickle ou msgpack
   # MultiplicaÃ§Ã£o otimizada: np.dot()
   ```

2. **Timeout e Retry**:
   ```python
   sock.settimeout(30)  # 30 segundos
   # Redistribuir tarefa se timeout
   ```

3. **DivisÃ£o DinÃ¢mica**:
   ```python
   # Servidor mantÃ©m fila de tarefas
   # Clientes pedem nova tarefa ao terminar
   ```

4. **MÃ©tricas Detalhadas**:
   ```python
   # Tempo de cada etapa
   # Throughput (elementos/segundo)
   # EficiÃªncia (speedup/num_clients)
   ```

---

## ðŸ“š ReferÃªncias TeÃ³ricas

### Algoritmos de MultiplicaÃ§Ã£o de Matrizes

1. **ClÃ¡ssico** (usado no projeto): O(nÂ³)
2. **Strassen**: O(n^2.807)
3. **Coppersmith-Winograd**: O(n^2.376)

### Modelos de ProgramaÃ§Ã£o Paralela

1. **SPMD** (Single Program, Multiple Data): Usado no projeto
2. **Master-Worker**: Arquitetura do projeto
3. **MapReduce**: PossÃ­vel extensÃ£o

### Lei de Amdahl

```
Speedup_max = 1 / (s + (p / N))

s = fraÃ§Ã£o sequencial (overhead)
p = fraÃ§Ã£o paralelizÃ¡vel
N = nÃºmero de processadores
```

**AplicaÃ§Ã£o ao projeto**:
- p â‰ˆ 0.95 (cÃ¡lculo da multiplicaÃ§Ã£o)
- s â‰ˆ 0.05 (comunicaÃ§Ã£o, sincronizaÃ§Ã£o)
- Speedup_max(4 clientes) â‰ˆ 3.48

---

## ðŸŽ¤ Roteiro de ApresentaÃ§Ã£o Sugerido

### 1. IntroduÃ§Ã£o (2 min)
- Problema: MultiplicaÃ§Ã£o de matrizes grandes
- SoluÃ§Ã£o: Distribuir processamento

### 2. Arquitetura (3 min)
- Diagrama cliente-servidor
- DivisÃ£o em blocos
- Protocolo de comunicaÃ§Ã£o

### 3. Conceitos de Paralelismo (3 min)
- Paralelismo de dados
- Threading vs Multiprocessing
- SincronizaÃ§Ã£o com locks

### 4. DemonstraÃ§Ã£o (5 min)
- Executar com 3 clientes
- Mostrar logs
- Comparar tempos

### 5. AnÃ¡lise de Desempenho (3 min)
- GrÃ¡fico speedup vs clientes
- Overhead de comunicaÃ§Ã£o
- Lei de Amdahl

### 6. ConclusÃµes (2 min)
- Ganhos obtidos
- LimitaÃ§Ãµes
- Trabalhos futuros

---

## ðŸ’¡ Perguntas Frequentes

**Q: Por que dividir por linhas e nÃ£o por colunas?**
A: Linhas de A sÃ£o independentes no cÃ¡lculo. Dividir B seria mais complexo.

**Q: Por que usar JSON e nÃ£o formato binÃ¡rio?**
A: Simplicidade e debugging. Para produÃ§Ã£o, usar pickle ou msgpack.

**Q: Funciona com clientes em mÃ¡quinas diferentes?**
A: Sim! Basta mudar HOST para IP da mÃ¡quina do servidor.

**Q: Quantos clientes Ã© ideal?**
A: Depende do tamanho da matriz. Testar empiricamente.

**Q: Por que threading no servidor e nÃ£o multiprocessing?**
A: Threads sÃ£o suficientes pois servidor sÃ³ faz I/O (nÃ£o CPU-bound).

---

## ðŸ“ Checklist para ApresentaÃ§Ã£o

- [ ] Entender fluxo completo (inicializaÃ§Ã£o â†’ validaÃ§Ã£o)
- [ ] Saber explicar cada funÃ§Ã£o principal
- [ ] Preparar demonstraÃ§Ã£o ao vivo
- [ ] Ter grÃ¡ficos de desempenho (se possÃ­vel)
- [ ] Conhecer limitaÃ§Ãµes e melhorias
- [ ] Revisar conceitos: paralelismo, concorrÃªncia, locks
- [ ] Preparar respostas para perguntas frequentes

---

**Boa sorte na apresentaÃ§Ã£o! ðŸš€**
